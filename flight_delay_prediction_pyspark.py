# -*- coding: utf-8 -*-
"""Flight Delay Prediction PySpark.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/161U8k8pcHIwNq-BVrH374JEGKrdfjCTO
"""

!pip install pyspark

from pyspark.sql import SparkSession

spark=SparkSession.builder.appName('Dataframe').getOrCreate()

spark

df_pyspark=spark.read.option('header','true').csv('/content/flights-larger.csv',inferSchema=True) #to get int value we use inferschema

df_pyspark.printSchema()

type(df_pyspark) #dataframe is a data structure

df_pyspark.columns

df_pyspark.head() #different from panda , it shows in list format

df_pyspark.select('carrier')

df_pyspark.select('carrier').show()

df_pyspark.select(['carrier','dom']).show()

df_pyspark['dom'].show() #unlike pandas

df_pyspark.describe().show()

##adding and dropping columns


df_pyspark.withColumn('mon after 2',df_pyspark['mon']+2)

df_pyspark.withColumn('mon after 2',df_pyspark['mon']+2).show()

#dropping columns

df_pyspark.drop('mon after 2')

df_pyspark.show()

# rename columns

df_pyspark.withColumnRenamed('MMon','mon').show()



"""#**Flight Delay Prediction**"""

import numpy as np
import pandas as pd 
import os
import pyspark
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType, StringType

from pyspark.sql.functions import round
from pyspark.ml.feature import StringIndexer
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.classification import DecisionTreeClassifier
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator

spark = SparkSession.builder \
                    .master('local[*]') \
                    .appName('ML with PySpark') \
                    .getOrCreate()
spark

flights_df = spark.read.csv('/content/flights-larger.csv',sep=',',header=True,inferSchema=True,nullValue='NA')

print("The data contain %d records." % flights_df.count())

flights_df.show(5)

flights_df.dtypes

flights_df =  flights_df.drop('flight')
flights_df = flights_df.dropna()
print(flights_df.count())

flights_km = flights_df.withColumn('km', round(flights_df.mile * 1.60934, 0)) \
                    .drop('mile')


flights_km = flights_km.withColumn('label', (flights_km.delay >= 15).cast('integer'))

flights_km.show(5)

flights_indexed = StringIndexer(inputCol='carrier', outputCol='carrier_idx').fit(flights_km).transform(flights_km)


flights_indexed = StringIndexer(inputCol='org', outputCol='org_idx').fit(flights_indexed).transform(flights_indexed)
flights_indexed.show(5)

assembler = VectorAssembler(inputCols=['mon', 'dom', 'dow','carrier_idx', 'org_idx', 'km', 'depart', 'duration'], outputCol='features')

flights_assembled = assembler.transform(flights_indexed)

flights_assembled.select('features', 'delay').show(5, truncate=False)

"""Machine Learning Model"""

flights_train, flights_test = flights_assembled.randomSplit([0.8, 0.2], seed=42)


training_ratio = flights_train.count() / flights_assembled.count()
training_ratio

#using decision tree

tree = DecisionTreeClassifier()
tree_model = tree.fit(flights_train)

prediction = tree_model.transform(flights_test)
prediction.select('label', 'prediction', 'probability').show(5, False)

"""Evaluation of the model"""

prediction.groupBy('label', 'prediction').count().show()

# Calculate the elements of the confusion matrix
TN = prediction.filter('prediction = 0 AND label = prediction').count()
TP = prediction.filter('prediction = 1 AND label = prediction').count()
FN = prediction.filter('prediction = 0 AND label != prediction').count()
FP = prediction.filter('prediction = 1 AND label != prediction').count()


accuracy = (TN + TP) / (TN + TP + FN + FP)
accuracy

#using logistic regression

logistic = LogisticRegression().fit(flights_train)

prediction = logistic.transform(flights_test)
prediction.groupBy('label', 'prediction').count().show()

# Calculate precision and recall
precision = TP / (TP + FP)
recall = TP / (TP + FN)
print('precision = {:.2f}\nrecall    = {:.2f}'.format(precision, recall))

# Find weighted precision
multi_evaluator = MulticlassClassificationEvaluator()
weighted_precision = multi_evaluator.evaluate(prediction, {multi_evaluator.metricName: "weightedPrecision"})

# Find AUC
binary_evaluator = BinaryClassificationEvaluator()
auc = binary_evaluator.evaluate(prediction, {binary_evaluator.metricName: "areaUnderROC"})